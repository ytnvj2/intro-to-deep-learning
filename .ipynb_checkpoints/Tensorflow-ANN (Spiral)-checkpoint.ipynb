{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytnvj\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "## Creating Data\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def get_spiral():\n",
    "    # Idea: radius -> low...high\n",
    "    #           (don't start at 0, otherwise points will be \"mushed\" at origin)\n",
    "    #       angle = low...high proportional to radius\n",
    "    #               [0, 2pi/6, 4pi/6, ..., 10pi/6] --> [pi/2, pi/3 + pi/2, ..., ]\n",
    "    # x = rcos(theta), y = rsin(theta) as usual\n",
    "\n",
    "    radius = np.linspace(1, 10, 1000)\n",
    "    thetas = np.empty((6, 1000))\n",
    "    for i in range(6):\n",
    "        start_angle = np.pi*i / 3.0\n",
    "        end_angle = start_angle + np.pi / 2\n",
    "        points = np.linspace(start_angle, end_angle, 1000)\n",
    "        thetas[i] = points\n",
    "\n",
    "    # convert into cartesian coordinates\n",
    "    x1 = np.empty((6, 1000))\n",
    "    x2 = np.empty((6, 1000))\n",
    "    for i in range(6):\n",
    "        x1[i] = radius * np.cos(thetas[i])\n",
    "        x2[i] = radius * np.sin(thetas[i])\n",
    "\n",
    "    # inputs\n",
    "    X = np.empty((6000, 2))\n",
    "    X[:,0] = x1.flatten()\n",
    "    X[:,1] = x2.flatten()\n",
    "\n",
    "    # add noise\n",
    "    X += np.random.randn(6000, 2)*0.5\n",
    "\n",
    "    # targets\n",
    "    Y = np.array([0]*1000 + [1]*1000 + [2]*1000 + [0]*1000 + [3]*1000 + [2]*1000)\n",
    "    return X, Y\n",
    "\n",
    "X,y=get_spiral()\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1],c=y)\n",
    "plt.show()\n",
    "\n",
    "## Processing the Data\n",
    "\n",
    "def one_hot_encoder(X):\n",
    "    N=X.shape[0]\n",
    "    K=len(np.unique(X))\n",
    "    Z=np.zeros((N,K))\n",
    "    for i in range(N):\n",
    "        c=int(X[i])\n",
    "        Z[i,c]=1\n",
    "    return Z\n",
    "y_i=one_hot_encoder(y)\n",
    "\n",
    "def standardize(X):\n",
    "    stds=X.std(axis=0)\n",
    "    means=X.mean(axis=0)\n",
    "    X=(X-means)/stds\n",
    "    return X,means,stds\n",
    "\n",
    "X_s,m,s=standardize(X)\n",
    "\n",
    "def train_test_split(X,y,size=0.8,rs=None):\n",
    "    N=len(X)\n",
    "    np.random.seed(rs)\n",
    "    tr_i=np.random.choice(N,int(size*N),replace=False)\n",
    "    t_i=[i for i in range(N) if i not in tr_i]\n",
    "    X_train=X[tr_i]\n",
    "    y_train=y[tr_i]\n",
    "    X_test=X[t_i]\n",
    "    y_test=y[t_i]\n",
    "    return X_train,y_train,X_test,y_test\n",
    "X_train,y_train,X_test,y_test=train_test_split(X_s,y,size=0.9,rs=20)\n",
    "\n",
    "X_train=X_train.astype(np.float32)\n",
    "y_train=y_train.astype(np.float32)\n",
    "X_test=X_test.astype(np.float32)\n",
    "y_test=y_test.astype(np.float32)\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class HiddenLayer(object):\n",
    "    def __init__(self,i,M1,M2,af='relu',rs=None):\n",
    "        self.id=i\n",
    "        self.M1=M1\n",
    "        self.M2=M2\n",
    "        self.af=af\n",
    "        \n",
    "        self.W=tf.Variable(tf.random_normal(shape=[M1,M2],stddev=np.sqrt(M1),seed=rs,dtype=tf.float32))\n",
    "        self.b=tf.Variable(tf.random_normal(shape=[M2],seed=rs,dtype=tf.float32))\n",
    "        self.params=[self.W,self.b]\n",
    "    def forward(self,X):\n",
    "        if self.af=='tanh':\n",
    "            return tf.nn.tanh(tf.matmul(X,self.W)+self.b)\n",
    "        if self.af=='sigmoid':\n",
    "            return tf.nn.sigmoid(tf.matmul(X,self.W)+self.b)\n",
    "        if self.af=='relu':\n",
    "            return tf.nn.relu(tf.matmul(X,self.W)+self.b)\n",
    "        if self.af=='leaky-relu':\n",
    "            return tf.nn.leaky_relu(tf.matmul(X,self.W)+self.b)\n",
    "\n",
    "class ANN(object):\n",
    "    def __init__(self,hidden_layer_size):\n",
    "        self.hidden_layer_size=hidden_layer_size\n",
    "        \n",
    "    def forward(self,X):\n",
    "        z=X\n",
    "        for h in self.hidden_layers:\n",
    "            z=h.forward(z)\n",
    "        return tf.matmul(z,self.W)+self.b\n",
    "    \n",
    "    def predict(self,X):\n",
    "        p=self.forward(X)\n",
    "        return tf.argmax(p,axis=1)\n",
    "    \n",
    "    def fit(self,X,y,lr=0.001,epochs=1000,af=None,fig=True,batch_size=2900,n_batch=10,random_state=None):\n",
    "        y=one_hot_encoder(y)\n",
    "        if af==None:\n",
    "            af=len(self.hidden_layer_size)*['relu']\n",
    "        X_t,y_t,X_v,y_v=train_test_split(X,y,size=0.9,rs=random_state)\n",
    "        c_t=[]\n",
    "        c_v=[]\n",
    "        cl_t=[]\n",
    "        cl_v=[]\n",
    "        N,D=X_t.shape\n",
    "        self.hidden_layers=[]\n",
    "        M1=D\n",
    "        cnt=0\n",
    "        for M2,a in zip(self.hidden_layer_size,af):\n",
    "            h=HiddenLayer(cnt,M1,M2,a,random_state)\n",
    "            self.hidden_layers.append(h)\n",
    "            M1=M2\n",
    "            cnt+=1\n",
    "        M2=y.shape[1]\n",
    "        self.W=tf.Variable(tf.random_normal([M1,M2],stddev=np.sqrt(M1),seed=random_state,dtype=tf.float32))\n",
    "        self.b=tf.Variable(tf.random_normal(shape=[M2],seed=random_state,dtype=tf.float32))\n",
    "        self.params=[self.W,self.b]\n",
    "        for h in self.hidden_layers:\n",
    "            self.params+=h.params\n",
    "        tfX=tf.placeholder(tf.float32,shape=[None,D])\n",
    "        tfY=tf.placeholder(tf.float32,shape=[None,M2])\n",
    "        y_p=self.forward(tfX)\n",
    "        cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_p,labels=tfY))\n",
    "        preds=self.predict(tfX)\n",
    "        optimizer=tf.train.RMSPropOptimizer(lr)\n",
    "        train=optimizer.minimize(cost)\n",
    "        with tf.Session() as s:\n",
    "            s.run(tf.global_variables_initializer())\n",
    "            for i in range(epochs):\n",
    "                for j in range(n_batch):\n",
    "                    x=X_t[j*batch_size:(j*batch_size+batch_size)]\n",
    "                    yb=y_t[j*batch_size:j*batch_size+batch_size]\n",
    "                    c_t.append(s.run(cost,feed_dict={tfX:x,tfY:yb}))\n",
    "                    c_v.append(s.run(cost,feed_dict={tfX:X_v,tfY:y_v}))\n",
    "                    cl_t.append(np.mean(s.run(preds,feed_dict={tfX:x})==np.argmax(yb,axis=1)))               \n",
    "                    cl_v.append(np.mean(s.run(preds,feed_dict={tfX:X_v})==np.argmax(y_v,axis=1)))    \n",
    "                    s.run(train,feed_dict={tfX:x,tfY:yb})\n",
    "#                 c_t.append(s.run(cost,feed_dict={tfX:X_t,tfY:y_t}))\n",
    "#                 c_v.append(s.run(cost,feed_dict={tfX:X_v,tfY:y_v}))\n",
    "#                 cl_t.append(np.mean(s.run(preds,feed_dict={tfX:X_t})==np.argmax(y_t,axis=1)))               \n",
    "#                 cl_v.append(np.mean(s.run(preds,feed_dict={tfX:X_v})==np.argmax(y_v,axis=1)))    \n",
    "#                 s.run(train,feed_dict={tfX:X_t,tfY:y_t})   \n",
    "                if i%100==0:\n",
    "                    print('Epoch {0} Train C: {1} Cl: {2} Test C: {3} Cl:{4}'.format(i,c_t[i],cl_t[i],c_v[i],cl_v[i]))\n",
    "        if fig==True:\n",
    "            plt.plot(c_t,label='Train Cost')\n",
    "            plt.plot(c_v,label='Test Cost')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            plt.plot(cl_t,label='Train Classification')\n",
    "            plt.plot(cl_v,label='Test Classification')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=ANN((10,20,30))\n",
    "a.fit(X_train,y_train,lr=0.001,epochs=3000,batch_size=540,n_batch=10,af=['sigmoid','leaky-relu','relu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
